{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Installing dependencies"
      ],
      "metadata": {
        "id": "4J6fKOCDHBIX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdiBraUBCQU8",
        "outputId": "4288ad0e-9937-4eff-90a5-5ee48c3f4ae3",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "octave is already the newest version (6.4.0-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt install octave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xEQeOcuCR4X",
        "outputId": "b59ab750-18da-4563-8ef1-fac19733fd75",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.5.1+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh2XrowdCVdB",
        "outputId": "3e31fd52-8e2e-420d-f35b-a9ef9e2117df",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: oct2py in /usr/local/lib/python3.11/dist-packages (5.8.0)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.11/dist-packages (from oct2py) (1.26.4)\n",
            "Requirement already satisfied: octave-kernel>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from oct2py) (0.36.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.11/dist-packages (from oct2py) (1.13.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from octave-kernel>=0.34.0->oct2py) (6.17.1)\n",
            "Requirement already satisfied: jupyter-client>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from octave-kernel>=0.34.0->oct2py) (6.1.12)\n",
            "Requirement already satisfied: metakernel>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from octave-kernel>=0.34.0->oct2py) (0.30.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=4.3.0->octave-kernel>=0.34.0->oct2py) (5.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=4.3.0->octave-kernel>=0.34.0->oct2py) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=4.3.0->octave-kernel>=0.34.0->oct2py) (24.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=4.3.0->octave-kernel>=0.34.0->oct2py) (2.8.2)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=4.3.0->octave-kernel>=0.34.0->oct2py) (6.4.2)\n",
            "Requirement already satisfied: jedi>=0.18 in /usr/local/lib/python3.11/dist-packages (from metakernel>=0.24.0->octave-kernel>=0.34.0->oct2py) (0.19.2)\n",
            "Requirement already satisfied: pexpect>=4.8 in /usr/local/lib/python3.11/dist-packages (from metakernel>=0.24.0->octave-kernel>=0.34.0->oct2py) (4.9.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->octave-kernel>=0.34.0->oct2py) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->octave-kernel>=0.34.0->oct2py) (7.34.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->octave-kernel>=0.34.0->oct2py) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->octave-kernel>=0.34.0->oct2py) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel->octave-kernel>=0.34.0->oct2py) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->octave-kernel>=0.34.0->oct2py) (5.9.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->octave-kernel>=0.34.0->oct2py) (75.1.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->octave-kernel>=0.34.0->oct2py) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->octave-kernel>=0.34.0->oct2py) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->octave-kernel>=0.34.0->oct2py) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->octave-kernel>=0.34.0->oct2py) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->octave-kernel>=0.34.0->oct2py) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.18->metakernel>=0.24.0->octave-kernel>=0.34.0->oct2py) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=4.3.0->octave-kernel>=0.34.0->oct2py) (4.3.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>=4.8->metakernel>=0.24.0->octave-kernel>=0.34.0->oct2py) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client>=4.3.0->octave-kernel>=0.34.0->oct2py) (1.17.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->octave-kernel>=0.34.0->oct2py) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "!pip install oct2py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing Pkgs"
      ],
      "metadata": {
        "id": "ZTtUelClHiwL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GkASk1ntCWwA"
      },
      "outputs": [],
      "source": [
        "from oct2py import Oct2Py\n",
        "\n",
        "oc = Oct2Py();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v4TikcPJCYMq"
      },
      "outputs": [],
      "source": [
        "import torch;\n",
        "import torch.nn as nn;\n",
        "import torch.nn.functional as F;\n",
        "from torch.utils.data import Dataset, DataLoader;\n",
        "\n",
        "import matplotlib.pyplot as plt;\n",
        "import numpy as np;\n",
        "\n",
        "from tqdm import tqdm;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZhWeG9VtCZaO"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.classification import Accuracy,Precision, Recall, F1Score, ConfusionMatrix;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Z7naOC64CabM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd;\n",
        "import random;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5srtDDE-Cbsp"
      },
      "outputs": [],
      "source": [
        "import json;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gZdxk-lSCclp"
      },
      "outputs": [],
      "source": [
        "import os;\n",
        "import os.path;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2a7Bb_3tCdhI"
      },
      "outputs": [],
      "source": [
        "import re;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZwZSLDgCe6C",
        "outputId": "d8357894-43c7-49a5-d534-2708478c8865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\");\n",
        "print(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_cx5h_2qCf0t"
      },
      "outputs": [],
      "source": [
        "seed = 42;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ic9oNWkkCg4J"
      },
      "outputs": [],
      "source": [
        "np.random.seed(seed);\n",
        "random.seed(seed);\n",
        "torch.manual_seed(seed);\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed);\n",
        "    torch.cuda.manual_seed_all(seed);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m3-f42xcCg6v"
      },
      "outputs": [],
      "source": [
        "def getYLabel(filename):\n",
        "    output = {\n",
        "            \"K\" : 0,\n",
        "            \"KA\" : 1,\n",
        "            \"KI\" : 2\n",
        "    };\n",
        "\n",
        "    code = filename.split(\"_\")[3];\n",
        "\n",
        "    if code.startswith(\"KA\"):\n",
        "        return output[\"KA\"];\n",
        "    elif code.startswith(\"KI\"):\n",
        "        return output[\"KI\"];\n",
        "    else:\n",
        "        return output[\"K\"];"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset Creation"
      ],
      "metadata": {
        "id": "XJY-5cWdHo6R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6tH9vL25Cg9B"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, code, healty_end_points, faulty_end_points, oc, width, signal=\"vibration\"):\n",
        "        self.root_dir = root_dir;\n",
        "        self.healty_end_points = healty_end_points;\n",
        "        self.faulty_end_points = faulty_end_points;\n",
        "        self.oc = oc;\n",
        "\n",
        "        self.width = width;\n",
        "\n",
        "        self.X = [];\n",
        "        self.Y = [];\n",
        "\n",
        "        self.signal = signal;\n",
        "\n",
        "        for healty_end_point in self.healty_end_points:\n",
        "            for mat_healthy_end_point in os.listdir(os.path.join(self.root_dir, healty_end_point)):\n",
        "                if mat_healthy_end_point.endswith(\".mat\") and mat_healthy_end_point.startswith(code):\n",
        "                    self.X.append(os.path.join(self.root_dir, healty_end_point, mat_healthy_end_point));\n",
        "                    self.Y.append(getYLabel(mat_healthy_end_point));\n",
        "\n",
        "        for faulty_end_point in self.faulty_end_points:\n",
        "            for mat_faulty_end_point in os.listdir(os.path.join(self.root_dir, faulty_end_point)):\n",
        "                if mat_faulty_end_point.endswith(\".mat\") and mat_faulty_end_point.startswith(code):\n",
        "                    self.X.append(os.path.join(self.root_dir, faulty_end_point, mat_faulty_end_point));\n",
        "                    self.Y.append(getYLabel(mat_faulty_end_point));\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X);\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.oc.load(self.X[idx]);\n",
        "        field = list(data.keys())[0];\n",
        "\n",
        "        x = data[field]['Y']['Data'][0][6].flatten();\n",
        "\n",
        "        w = x.shape[-1];\n",
        "\n",
        "        if(w < self.width):\n",
        "            x = np.pad(x, pad_width = (0, self.width - w), mode = 'constant');\n",
        "        elif(w > self.width):\n",
        "            x = x[:self.width];\n",
        "\n",
        "\n",
        "        y = torch.full((250,),self.Y[idx]).to(torch.long);\n",
        "        X = torch.tensor(x).to(torch.float32);\n",
        "\n",
        "        X = X - X.mean();\n",
        "        X = X / X.std();\n",
        "\n",
        "        return X.reshape(250,1024), y;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "evr3whxBCkud"
      },
      "outputs": [],
      "source": [
        "def getCode(N, M, F):\n",
        "    return f\"N{N:02}\" + \"_\" + f\"M{M:02}\" + \"_\" + f\"F{F:02}\";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NfjnhEPVCg_X"
      },
      "outputs": [],
      "source": [
        "code = getCode(15, 7, 10);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c4-B1YsTCnhK"
      },
      "outputs": [],
      "source": [
        "# ratios = {2:5, 6:5, 8:5}\n",
        "def getDataset(code, signal = \"vibration\", width=256000, ratios=\"6:5\"):\n",
        "    root_dir = \"/content/drive/MyDrive/PaderbornExtracted\";\n",
        "    healty_end_points = [\"K001\",\"K002\",\"K003\",\"K004\",\"K005\",\"K006\"];\n",
        "    faulty_end_points_inner = [\"KI04\",\"KI14\",\"KI16\",\"KI17\",\"KI18\",\"KI21\"];\n",
        "    faulty_end_points_outer = [\"KA04\",\"KA15\",\"KA16\",\"KA22\",\"KA30\"];\n",
        "\n",
        "    f,h = ratios.split(\":\");\n",
        "\n",
        "    f,h = int(f), int(h);\n",
        "\n",
        "    healthy_training_end_points = healty_end_points[:h];\n",
        "    healthy_testing_end_points = healty_end_points[h:];\n",
        "\n",
        "    faulty_training_end_points = faulty_end_points_inner[:f//2] + faulty_end_points_outer[:f//2];\n",
        "    faulty_testing_end_points = faulty_end_points_inner[f//2:] + faulty_end_points_outer[f//2:];\n",
        "\n",
        "    train_dataset = CustomDataset(root_dir, code, healthy_training_end_points, faulty_training_end_points, oc, width, signal);\n",
        "    test_dataset = CustomDataset(root_dir, code, healthy_testing_end_points, faulty_testing_end_points, oc, width, signal);\n",
        "\n",
        "    return train_dataset, test_dataset;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R7cQ0Kv5CrdK",
        "outputId": "0e6f7259-75c5-4089-fe13-24ebb3c78e4c",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N15_M07_F10_K001_1.mat\n",
            "N15_M07_F10_K001_2.mat\n",
            "N15_M07_F10_K001_3.mat\n",
            "N15_M07_F10_K001_4.mat\n",
            "N15_M07_F10_K001_5.mat\n",
            "N15_M07_F10_K001_6.mat\n",
            "N15_M07_F10_K001_7.mat\n",
            "N15_M07_F10_K001_8.mat\n",
            "N15_M07_F10_K001_9.mat\n",
            "N15_M07_F10_K001_10.mat\n",
            "N15_M07_F10_K001_11.mat\n",
            "N15_M07_F10_K001_12.mat\n",
            "N15_M07_F10_K001_13.mat\n",
            "N15_M07_F10_K001_14.mat\n",
            "N15_M07_F10_K001_15.mat\n",
            "N15_M07_F10_K001_16.mat\n",
            "N15_M07_F10_K001_17.mat\n",
            "N15_M07_F10_K001_18.mat\n",
            "N15_M07_F10_K001_20.mat\n",
            "N15_M07_F10_K001_19.mat\n",
            "N15_M07_F10_K002_1.mat\n",
            "N15_M07_F10_K002_2.mat\n",
            "N15_M07_F10_K002_4.mat\n",
            "N15_M07_F10_K002_5.mat\n",
            "N15_M07_F10_K002_6.mat\n",
            "N15_M07_F10_K002_11.mat\n",
            "N15_M07_F10_K002_14.mat\n",
            "N15_M07_F10_K002_15.mat\n",
            "N15_M07_F10_K002_17.mat\n",
            "N15_M07_F10_K002_20.mat\n",
            "N15_M07_F10_K002_3.mat\n",
            "N15_M07_F10_K002_7.mat\n",
            "N15_M07_F10_K002_8.mat\n",
            "N15_M07_F10_K002_10.mat\n",
            "N15_M07_F10_K002_13.mat\n",
            "N15_M07_F10_K002_16.mat\n",
            "N15_M07_F10_K002_9.mat\n",
            "N15_M07_F10_K002_12.mat\n",
            "N15_M07_F10_K002_19.mat\n",
            "N15_M07_F10_K002_18.mat\n",
            "N15_M07_F10_K003_1.mat\n",
            "N15_M07_F10_K003_2.mat\n",
            "N15_M07_F10_K003_3.mat\n",
            "N15_M07_F10_K003_4.mat\n",
            "N15_M07_F10_K003_5.mat\n",
            "N15_M07_F10_K003_6.mat\n",
            "N15_M07_F10_K003_7.mat\n",
            "N15_M07_F10_K003_8.mat\n",
            "N15_M07_F10_K003_9.mat\n",
            "N15_M07_F10_K003_10.mat\n",
            "N15_M07_F10_K003_11.mat\n",
            "N15_M07_F10_K003_12.mat\n",
            "N15_M07_F10_K003_13.mat\n",
            "N15_M07_F10_K003_14.mat\n",
            "N15_M07_F10_K003_15.mat\n",
            "N15_M07_F10_K003_16.mat\n",
            "N15_M07_F10_K003_17.mat\n",
            "N15_M07_F10_K003_18.mat\n",
            "N15_M07_F10_K003_19.mat\n",
            "N15_M07_F10_K003_20.mat\n",
            "N15_M07_F10_K004_1.mat\n",
            "N15_M07_F10_K004_2.mat\n",
            "N15_M07_F10_K004_3.mat\n",
            "N15_M07_F10_K004_4.mat\n",
            "N15_M07_F10_K004_5.mat\n",
            "N15_M07_F10_K004_6.mat\n",
            "N15_M07_F10_K004_7.mat\n",
            "N15_M07_F10_K004_8.mat\n",
            "N15_M07_F10_K004_9.mat\n",
            "N15_M07_F10_K004_10.mat\n",
            "N15_M07_F10_K004_11.mat\n",
            "N15_M07_F10_K004_12.mat\n",
            "N15_M07_F10_K004_13.mat\n",
            "N15_M07_F10_K004_14.mat\n",
            "N15_M07_F10_K004_15.mat\n",
            "N15_M07_F10_K004_16.mat\n",
            "N15_M07_F10_K004_17.mat\n",
            "N15_M07_F10_K004_18.mat\n",
            "N15_M07_F10_K004_19.mat\n",
            "N15_M07_F10_K004_20.mat\n",
            "N15_M07_F10_K005_1.mat\n",
            "N15_M07_F10_K005_2.mat\n",
            "N15_M07_F10_K005_3.mat\n",
            "N15_M07_F10_K005_4.mat\n",
            "N15_M07_F10_K005_5.mat\n",
            "N15_M07_F10_K005_6.mat\n",
            "N15_M07_F10_K005_7.mat\n",
            "N15_M07_F10_K005_8.mat\n",
            "N15_M07_F10_K005_9.mat\n",
            "N15_M07_F10_K005_10.mat\n",
            "N15_M07_F10_K005_11.mat\n",
            "N15_M07_F10_K005_12.mat\n",
            "N15_M07_F10_K005_13.mat\n",
            "N15_M07_F10_K005_14.mat\n",
            "N15_M07_F10_K005_15.mat\n",
            "N15_M07_F10_K005_16.mat\n",
            "N15_M07_F10_K005_17.mat\n",
            "N15_M07_F10_K005_18.mat\n",
            "N15_M07_F10_K005_19.mat\n",
            "N15_M07_F10_K005_20.mat\n",
            "N15_M07_F10_KI04_1.mat\n",
            "N15_M07_F10_KI04_2.mat\n",
            "N15_M07_F10_KI04_3.mat\n",
            "N15_M07_F10_KI04_4.mat\n",
            "N15_M07_F10_KI04_5.mat\n",
            "N15_M07_F10_KI04_6.mat\n",
            "N15_M07_F10_KI04_7.mat\n",
            "N15_M07_F10_KI04_8.mat\n",
            "N15_M07_F10_KI04_9.mat\n",
            "N15_M07_F10_KI04_10.mat\n",
            "N15_M07_F10_KI04_11.mat\n",
            "N15_M07_F10_KI04_12.mat\n",
            "N15_M07_F10_KI04_13.mat\n",
            "N15_M07_F10_KI04_14.mat\n",
            "N15_M07_F10_KI04_15.mat\n",
            "N15_M07_F10_KI04_16.mat\n",
            "N15_M07_F10_KI04_17.mat\n",
            "N15_M07_F10_KI04_18.mat\n",
            "N15_M07_F10_KI04_19.mat\n",
            "N15_M07_F10_KI04_20.mat\n",
            "N15_M07_F10_KI14_1.mat\n",
            "N15_M07_F10_KI14_2.mat\n",
            "N15_M07_F10_KI14_3.mat\n",
            "N15_M07_F10_KI14_4.mat\n",
            "N15_M07_F10_KI14_5.mat\n",
            "N15_M07_F10_KI14_6.mat\n",
            "N15_M07_F10_KI14_7.mat\n",
            "N15_M07_F10_KI14_8.mat\n",
            "N15_M07_F10_KI14_9.mat\n",
            "N15_M07_F10_KI14_10.mat\n",
            "N15_M07_F10_KI14_11.mat\n",
            "N15_M07_F10_KI14_12.mat\n",
            "N15_M07_F10_KI14_13.mat\n",
            "N15_M07_F10_KI14_14.mat\n",
            "N15_M07_F10_KI14_15.mat\n",
            "N15_M07_F10_KI14_16.mat\n",
            "N15_M07_F10_KI14_17.mat\n",
            "N15_M07_F10_KI14_18.mat\n",
            "N15_M07_F10_KI14_19.mat\n",
            "N15_M07_F10_KI14_20.mat\n",
            "N15_M07_F10_KI16_1.mat\n",
            "N15_M07_F10_KI16_2.mat\n",
            "N15_M07_F10_KI16_3.mat\n",
            "N15_M07_F10_KI16_4.mat\n",
            "N15_M07_F10_KI16_5.mat\n",
            "N15_M07_F10_KI16_6.mat\n",
            "N15_M07_F10_KI16_7.mat\n",
            "N15_M07_F10_KI16_8.mat\n",
            "N15_M07_F10_KI16_9.mat\n",
            "N15_M07_F10_KI16_10.mat\n",
            "N15_M07_F10_KI16_11.mat\n",
            "N15_M07_F10_KI16_12.mat\n",
            "N15_M07_F10_KI16_13.mat\n",
            "N15_M07_F10_KI16_14.mat\n",
            "N15_M07_F10_KI16_15.mat\n",
            "N15_M07_F10_KI16_16.mat\n",
            "N15_M07_F10_KI16_17.mat\n",
            "N15_M07_F10_KI16_18.mat\n",
            "N15_M07_F10_KI16_19.mat\n",
            "N15_M07_F10_KI16_20.mat\n",
            "N15_M07_F10_KA04_1.mat\n",
            "N15_M07_F10_KA04_2.mat\n",
            "N15_M07_F10_KA04_3.mat\n",
            "N15_M07_F10_KA04_4.mat\n",
            "N15_M07_F10_KA04_5.mat\n",
            "N15_M07_F10_KA04_6.mat\n",
            "N15_M07_F10_KA04_7.mat\n",
            "N15_M07_F10_KA04_8.mat\n",
            "N15_M07_F10_KA04_9.mat\n",
            "N15_M07_F10_KA04_10.mat\n",
            "N15_M07_F10_KA04_11.mat\n",
            "N15_M07_F10_KA04_14.mat\n",
            "N15_M07_F10_KA04_13.mat\n",
            "N15_M07_F10_KA04_12.mat\n",
            "N15_M07_F10_KA04_15.mat\n",
            "N15_M07_F10_KA04_16.mat\n",
            "N15_M07_F10_KA04_17.mat\n",
            "N15_M07_F10_KA04_18.mat\n",
            "N15_M07_F10_KA04_19.mat\n",
            "N15_M07_F10_KA04_20.mat\n",
            "N15_M07_F10_KA15_1.mat\n",
            "N15_M07_F10_KA15_2.mat\n",
            "N15_M07_F10_KA15_3.mat\n",
            "N15_M07_F10_KA15_4.mat\n",
            "N15_M07_F10_KA15_5.mat\n",
            "N15_M07_F10_KA15_6.mat\n",
            "N15_M07_F10_KA15_7.mat\n",
            "N15_M07_F10_KA15_8.mat\n",
            "N15_M07_F10_KA15_9.mat\n",
            "N15_M07_F10_KA15_10.mat\n",
            "N15_M07_F10_KA15_11.mat\n",
            "N15_M07_F10_KA15_12.mat\n",
            "N15_M07_F10_KA15_13.mat\n",
            "N15_M07_F10_KA15_14.mat\n",
            "N15_M07_F10_KA15_15.mat\n",
            "N15_M07_F10_KA15_16.mat\n",
            "N15_M07_F10_KA15_17.mat\n",
            "N15_M07_F10_KA15_18.mat\n",
            "N15_M07_F10_KA15_19.mat\n",
            "N15_M07_F10_KA15_20.mat\n",
            "N15_M07_F10_KA16_1.mat\n",
            "N15_M07_F10_KA16_2.mat\n",
            "N15_M07_F10_KA16_3.mat\n",
            "N15_M07_F10_KA16_4.mat\n",
            "N15_M07_F10_KA16_5.mat\n",
            "N15_M07_F10_KA16_6.mat\n",
            "N15_M07_F10_KA16_7.mat\n",
            "N15_M07_F10_KA16_8.mat\n",
            "N15_M07_F10_KA16_9.mat\n",
            "N15_M07_F10_KA16_10.mat\n",
            "N15_M07_F10_KA16_11.mat\n",
            "N15_M07_F10_KA16_12.mat\n",
            "N15_M07_F10_KA16_13.mat\n",
            "N15_M07_F10_KA16_14.mat\n",
            "N15_M07_F10_KA16_15.mat\n",
            "N15_M07_F10_KA16_16.mat\n",
            "N15_M07_F10_KA16_17.mat\n",
            "N15_M07_F10_KA16_18.mat\n",
            "N15_M07_F10_KA16_19.mat\n",
            "N15_M07_F10_KA16_20.mat\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIPxJREFUeJzt3XtU1HX+x/EXiFwyAS85wIZKrXlLLTUJtV+Wk1jm0ZOnpGMec007LbYpleme1LUb6rrq2pJUx9R2vaRb6najDENPhWhou1pmWpSUgdsFRjHR5PP7o59zmvCGDfKG3/NxzpzkO5/58vn4mXGeDQOEOOecAAAADAmt6wkAAAD8EoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAc8LqegLnoqqqSvv371fTpk0VEhJS19MBAABnwTmngwcPKiEhQaGhp3+NpF4Gyv79+5WYmFjX0wAAAOeguLhYF1988WnH1MtAadq0qaSfFhgdHV3HswEAAGfD5/MpMTHR/zx+OvUyUE58WSc6OppAAQCgnjmbt2fwJlkAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMypcaBs2rRJgwcPVkJCgkJCQrR27dqA651zmjZtmuLj4xUVFSWv16s9e/YEjPnuu+80YsQIRUdHKzY2VmPGjNGhQ4d+1UIAAEDDUeNAqaioULdu3ZSVlXXS62fPnq0FCxYoOztbBQUFatKkiVJTU3XkyBH/mBEjRujDDz/U+vXr9corr2jTpk0aN27cua8CAAA0KCHOOXfONw4J0Zo1azR06FBJP716kpCQoPvvv18PPPCAJKm8vFwej0dLlixRWlqadu3apU6dOmnr1q3q2bOnJCknJ0c33XSTvvzySyUkJJzx8/p8PsXExKi8vJxfFggAQD1Rk+fvoL4HpaioSCUlJfJ6vf5jMTExSk5OVn5+viQpPz9fsbGx/jiRJK/Xq9DQUBUUFJz0vJWVlfL5fAEXAADQcIUF82QlJSWSJI/HE3Dc4/H4ryspKVGrVq0CJxEWpubNm/vH/FJmZqZmzJgRzKmeVtvJr563zxUsn88cVNdTAAAgaOrFd/FMmTJF5eXl/ktxcXFdTwkAANSioAZKXFycJKm0tDTgeGlpqf+6uLg4HThwIOD6H3/8Ud99951/zC9FREQoOjo64AIAABquoAZKUlKS4uLilJub6z/m8/lUUFCglJQUSVJKSorKyspUWFjoH7NhwwZVVVUpOTk5mNMBAAD1VI3fg3Lo0CHt3bvX/3FRUZE++OADNW/eXK1bt9aECRP02GOPqV27dkpKStLUqVOVkJDg/06fjh07auDAgRo7dqyys7N17NgxjR8/XmlpaWf1HTwAAKDhq3GgvP/++7ruuuv8H2dkZEiSRo0apSVLlmjSpEmqqKjQuHHjVFZWpr59+yonJ0eRkZH+2yxbtkzjx49X//79FRoaqmHDhmnBggVBWA4AAGgIftXPQakrtf1zUPguHgAAgq/Ofg4KAABAMBAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYE/RAOX78uKZOnaqkpCRFRUXp0ksv1aOPPirnnH+Mc07Tpk1TfHy8oqKi5PV6tWfPnmBPBQAA1FNBD5RZs2Zp4cKF+tvf/qZdu3Zp1qxZmj17tp588kn/mNmzZ2vBggXKzs5WQUGBmjRpotTUVB05ciTY0wEAAPVQWLBP+N5772nIkCEaNGiQJKlt27ZasWKFtmzZIumnV0/mz5+vhx9+WEOGDJEkPf/88/J4PFq7dq3S0tKCPSUAAFDPBP0VlN69eys3N1effPKJJOnf//633nnnHd14442SpKKiIpWUlMjr9fpvExMTo+TkZOXn5wd7OgAAoB4K+isokydPls/nU4cOHdSoUSMdP35cjz/+uEaMGCFJKikpkSR5PJ6A23k8Hv91v1RZWanKykr/xz6fL9jTBgAAhgT9FZRVq1Zp2bJlWr58ubZt26alS5dqzpw5Wrp06TmfMzMzUzExMf5LYmJiEGcMAACsCXqgPPjgg5o8ebLS0tLUpUsXjRw5UhMnTlRmZqYkKS4uTpJUWloacLvS0lL/db80ZcoUlZeX+y/FxcXBnjYAADAk6IFy+PBhhYYGnrZRo0aqqqqSJCUlJSkuLk65ubn+630+nwoKCpSSknLSc0ZERCg6OjrgAgAAGq6gvwdl8ODBevzxx9W6dWt17txZ27dv19y5c/W73/1OkhQSEqIJEyboscceU7t27ZSUlKSpU6cqISFBQ4cODfZ0AABAPRT0QHnyySc1depU/f73v9eBAweUkJCgu+++W9OmTfOPmTRpkioqKjRu3DiVlZWpb9++ysnJUWRkZLCnAwAA6qEQ9/Mf8VpP+Hw+xcTEqLy8vFa+3NN28qtBP2dt+3zmoLqeAgAAp1WT529+Fw8AADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmEOgAAAAcwgUAABgDoECAADMIVAAAIA5BAoAADCHQAEAAOYQKAAAwBwCBQAAmFMrgfLVV1/pjjvuUIsWLRQVFaUuXbro/fff91/vnNO0adMUHx+vqKgoeb1e7dmzpzamAgAA6qGgB8r333+vPn36qHHjxnr99df10Ucf6S9/+YuaNWvmHzN79mwtWLBA2dnZKigoUJMmTZSamqojR44EezoAAKAeCgv2CWfNmqXExEQtXrzYfywpKcn/Z+ec5s+fr4cfflhDhgyRJD3//PPyeDxau3at0tLSgj0lAABQzwT9FZR//etf6tmzp2699Va1atVKV155pZ599ln/9UVFRSopKZHX6/Ufi4mJUXJysvLz8096zsrKSvl8voALAABouIL+Cspnn32mhQsXKiMjQ3/84x+1detW/eEPf1B4eLhGjRqlkpISSZLH4wm4ncfj8V/3S5mZmZoxY0awpwrAqLaTX63rKdTY5zMH1fUUYFR9vD9LdX+fDvorKFVVVerevbueeOIJXXnllRo3bpzGjh2r7Ozscz7nlClTVF5e7r8UFxcHccYAAMCaoAdKfHy8OnXqFHCsY8eO2rdvnyQpLi5OklRaWhowprS01H/dL0VERCg6OjrgAgAAGq6gB0qfPn20e/fugGOffPKJ2rRpI+mnN8zGxcUpNzfXf73P51NBQYFSUlKCPR0AAFAPBf09KBMnTlTv3r31xBNP6LbbbtOWLVv0zDPP6JlnnpEkhYSEaMKECXrsscfUrl07JSUlaerUqUpISNDQoUODPR0AAFAPBT1QrrrqKq1Zs0ZTpkzRI488oqSkJM2fP18jRozwj5k0aZIqKio0btw4lZWVqW/fvsrJyVFkZGSwpwMAAOqhoAeKJN188826+eabT3l9SEiIHnnkET3yyCO18ekBAEA9x+/iAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYU+uBMnPmTIWEhGjChAn+Y0eOHFF6erpatGihCy+8UMOGDVNpaWltTwUAANQTtRooW7du1dNPP62uXbsGHJ84caJefvllrV69Whs3btT+/ft1yy231OZUAABAPVJrgXLo0CGNGDFCzz77rJo1a+Y/Xl5erkWLFmnu3Lm6/vrr1aNHDy1evFjvvfeeNm/eXFvTAQAA9UitBUp6eroGDRokr9cbcLywsFDHjh0LON6hQwe1bt1a+fn5Jz1XZWWlfD5fwAUAADRcYbVx0pUrV2rbtm3aunVrtetKSkoUHh6u2NjYgOMej0clJSUnPV9mZqZmzJhRG1MFAAAGBf0VlOLiYt13331atmyZIiMjg3LOKVOmqLy83H8pLi4OynkBAIBNQQ+UwsJCHThwQN27d1dYWJjCwsK0ceNGLViwQGFhYfJ4PDp69KjKysoCbldaWqq4uLiTnjMiIkLR0dEBFwAA0HAF/Us8/fv3144dOwKOjR49Wh06dNBDDz2kxMRENW7cWLm5uRo2bJgkaffu3dq3b59SUlKCPR0AAFAPBT1QmjZtqssvvzzgWJMmTdSiRQv/8TFjxigjI0PNmzdXdHS07r33XqWkpOjqq68O9nQAAEA9VCtvkj2TefPmKTQ0VMOGDVNlZaVSU1P11FNP1cVUAACAQeclUPLy8gI+joyMVFZWlrKyss7HpwcAAPUMv4sHAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwJeqBkZmbqqquuUtOmTdWqVSsNHTpUu3fvDhhz5MgRpaenq0WLFrrwwgs1bNgwlZaWBnsqAACgngp6oGzcuFHp6enavHmz1q9fr2PHjmnAgAGqqKjwj5k4caJefvllrV69Whs3btT+/ft1yy23BHsqAACgngoL9glzcnICPl6yZIlatWqlwsJC/c///I/Ky8u1aNEiLV++XNdff70kafHixerYsaM2b96sq6++OthTAgAA9UytvwelvLxcktS8eXNJUmFhoY4dOyav1+sf06FDB7Vu3Vr5+fknPUdlZaV8Pl/ABQAANFy1GihVVVWaMGGC+vTpo8svv1ySVFJSovDwcMXGxgaM9Xg8KikpOel5MjMzFRMT478kJibW5rQBAEAdq9VASU9P186dO7Vy5cpfdZ4pU6aovLzcfykuLg7SDAEAgEVBfw/KCePHj9crr7yiTZs26eKLL/Yfj4uL09GjR1VWVhbwKkppaani4uJOeq6IiAhFRETU1lQBAIAxQX8FxTmn8ePHa82aNdqwYYOSkpICru/Ro4caN26s3Nxc/7Hdu3dr3759SklJCfZ0AABAPRT0V1DS09O1fPlyrVu3Tk2bNvW/ryQmJkZRUVGKiYnRmDFjlJGRoebNmys6Olr33nuvUlJS+A4eAAAgqRYCZeHChZKkfv36BRxfvHix7rzzTknSvHnzFBoaqmHDhqmyslKpqal66qmngj0VAABQTwU9UJxzZxwTGRmprKwsZWVlBfvTAwCABoDfxQMAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDkECgAAMKdOAyUrK0tt27ZVZGSkkpOTtWXLlrqcDgAAMKLOAuWFF15QRkaGpk+frm3btqlbt25KTU3VgQMH6mpKAADAiDoLlLlz52rs2LEaPXq0OnXqpOzsbF1wwQV67rnn6mpKAADAiLC6+KRHjx5VYWGhpkyZ4j8WGhoqr9er/Pz8auMrKytVWVnp/7i8vFyS5PP5amV+VZWHa+W8tam2/i6AusBjEA1Jfbw/S7Vznz5xTufcGcfWSaB88803On78uDweT8Bxj8ejjz/+uNr4zMxMzZgxo9rxxMTEWptjfRMzv65nAPz/xmMQDU1t3qcPHjyomJiY046pk0CpqSlTpigjI8P/cVVVlb777ju1aNFCISEhQf1cPp9PiYmJKi4uVnR0dFDPbQHrq/8a+hpZX/3X0NfY0Ncn1d4anXM6ePCgEhISzji2TgKlZcuWatSokUpLSwOOl5aWKi4urtr4iIgIRUREBByLjY2tzSkqOjq6wd7xJNbXEDT0NbK++q+hr7Ghr0+qnTWe6ZWTE+rkTbLh4eHq0aOHcnNz/ceqqqqUm5urlJSUupgSAAAwpM6+xJORkaFRo0apZ8+e6tWrl+bPn6+KigqNHj26rqYEAACMqLNAGT58uP773/9q2rRpKikp0RVXXKGcnJxqb5w93yIiIjR9+vRqX1JqKFhf/dfQ18j66r+GvsaGvj7JxhpD3Nl8rw8AAMB5xO/iAQAA5hAoAADAHAIFAACYQ6AAAABzGnygZGVlqW3btoqMjFRycrK2bNly2vGrV69Whw4dFBkZqS5duui1114LuN45p2nTpik+Pl5RUVHyer3as2dPbS7hjGqyxmeffVbXXHONmjVrpmbNmsnr9VYbf+eddyokJCTgMnDgwNpexinVZH1LliypNvfIyMiAMdb2sCbr69evX7X1hYSEaNCgQf4xlvZv06ZNGjx4sBISEhQSEqK1a9ee8TZ5eXnq3r27IiIi9Nvf/lZLliypNqamj+vaVNM1vvTSS7rhhht00UUXKTo6WikpKXrjjTcCxvzpT3+qtocdOnSoxVWcWk3Xl5eXd9L7aElJScA4K3tY0/Wd7PEVEhKizp07+8dY2r/MzExdddVVatq0qVq1aqWhQ4dq9+7dZ7ydhefCBh0oL7zwgjIyMjR9+nRt27ZN3bp1U2pqqg4cOHDS8e+9955uv/12jRkzRtu3b9fQoUM1dOhQ7dy50z9m9uzZWrBggbKzs1VQUKAmTZooNTVVR44cOV/LClDTNebl5en222/X22+/rfz8fCUmJmrAgAH66quvAsYNHDhQX3/9tf+yYsWK87Gcamq6Pumnn3z487l/8cUXAddb2sOaru+ll14KWNvOnTvVqFEj3XrrrQHjrOxfRUWFunXrpqysrLMaX1RUpEGDBum6667TBx98oAkTJuiuu+4KeAI/l/tEbarpGjdt2qQbbrhBr732mgoLC3Xddddp8ODB2r59e8C4zp07B+zhO++8UxvTP6Oaru+E3bt3B8y/VatW/uss7WFN1/fXv/41YF3FxcVq3rx5tceglf3buHGj0tPTtXnzZq1fv17Hjh3TgAEDVFFRccrbmHkudA1Yr169XHp6uv/j48ePu4SEBJeZmXnS8bfddpsbNGhQwLHk5GR39913O+ecq6qqcnFxce7Pf/6z//qysjIXERHhVqxYUQsrOLOarvGXfvzxR9e0aVO3dOlS/7FRo0a5IUOGBHuq56Sm61u8eLGLiYk55fms7eGv3b958+a5pk2bukOHDvmPWdq/n5Pk1qxZc9oxkyZNcp07dw44Nnz4cJeamur/+Nf+ndWms1njyXTq1MnNmDHD//H06dNdt27dgjexIDmb9b399ttOkvv+++9POcbqHp7L/q1Zs8aFhIS4zz//3H/M6v4559yBAwecJLdx48ZTjrHyXNhgX0E5evSoCgsL5fV6/cdCQ0Pl9XqVn59/0tvk5+cHjJek1NRU//iioiKVlJQEjImJiVFycvIpz1mbzmWNv3T48GEdO3ZMzZs3Dziel5enVq1aqX379rrnnnv07bffBnXuZ+Nc13fo0CG1adNGiYmJGjJkiD788EP/dZb2MBj7t2jRIqWlpalJkyYBxy3s37k402MwGH9n1lRVVengwYPVHoN79uxRQkKCLrnkEo0YMUL79u2roxmemyuuuELx8fG64YYb9O677/qPN7Q9XLRokbxer9q0aRNw3Or+lZeXS1K1+9vPWXkubLCB8s033+j48ePVfjKtx+Op9rXQE0pKSk47/sR/a3LO2nQua/ylhx56SAkJCQF3tIEDB+r5559Xbm6uZs2apY0bN+rGG2/U8ePHgzr/MzmX9bVv317PPfec1q1bp3/84x+qqqpS79699eWXX0qytYe/dv+2bNminTt36q677go4bmX/zsWpHoM+n08//PBDUO7z1syZM0eHDh3Sbbfd5j+WnJysJUuWKCcnRwsXLlRRUZGuueYaHTx4sA5nenbi4+OVnZ2tF198US+++KISExPVr18/bdu2TVJw/t2yYv/+/Xr99derPQat7l9VVZUmTJigPn366PLLLz/lOCvPhXX2o+5R92bOnKmVK1cqLy8v4I2kaWlp/j936dJFXbt21aWXXqq8vDz179+/LqZ61lJSUgJ+4WTv3r3VsWNHPf3003r00UfrcGbBt2jRInXp0kW9evUKOF6f9+//m+XLl2vGjBlat25dwHs0brzxRv+fu3btquTkZLVp00arVq3SmDFj6mKqZ619+/Zq3769/+PevXvr008/1bx58/T3v/+9DmcWfEuXLlVsbKyGDh0acNzq/qWnp2vnzp119n6Ymmqwr6C0bNlSjRo1UmlpacDx0tJSxcXFnfQ2cXFxpx1/4r81OWdtOpc1njBnzhzNnDlTb775prp27XrasZdccolatmypvXv3/uo518SvWd8JjRs31pVXXumfu6U9/DXrq6io0MqVK8/qH7u62r9zcarHYHR0tKKiooJyn7Bi5cqVuuuuu7Rq1apqL6f/UmxsrC677LJ6sYcn06tXL//cG8oeOuf03HPPaeTIkQoPDz/tWAv7N378eL3yyit6++23dfHFF592rJXnwgYbKOHh4erRo4dyc3P9x6qqqpSbmxvwf9g/l5KSEjBektavX+8fn5SUpLi4uIAxPp9PBQUFpzxnbTqXNUo/vfv60UcfVU5Ojnr27HnGz/Pll1/q22+/VXx8fFDmfbbOdX0/d/z4ce3YscM/d0t7+GvWt3r1alVWVuqOO+444+epq/07F2d6DAbjPmHBihUrNHr0aK1YsSLgW8RP5dChQ/r000/rxR6ezAcffOCfe0PZw40bN2rv3r1n9T8Jdbl/zjmNHz9ea9as0YYNG5SUlHTG25h5Lgza220NWrlypYuIiHBLlixxH330kRs3bpyLjY11JSUlzjnnRo4c6SZPnuwf/+6777qwsDA3Z84ct2vXLjd9+nTXuHFjt2PHDv+YmTNnutjYWLdu3Tr3n//8xw0ZMsQlJSW5H3744byvz7mar3HmzJkuPDzc/fOf/3Rff/21/3Lw4EHnnHMHDx50DzzwgMvPz3dFRUXurbfect27d3ft2rVzR44cMb++GTNmuDfeeMN9+umnrrCw0KWlpbnIyEj34Ycf+sdY2sOaru+Evn37uuHDh1c7bm3/Dh486LZv3+62b9/uJLm5c+e67du3uy+++MI559zkyZPdyJEj/eM/++wzd8EFF7gHH3zQ7dq1y2VlZblGjRq5nJwc/5gz/Z2dbzVd47Jly1xYWJjLysoKeAyWlZX5x9x///0uLy/PFRUVuXfffdd5vV7XsmVLd+DAAfPrmzdvnlu7dq3bs2eP27Fjh7vvvvtcaGioe+utt/xjLO1hTdd3wh133OGSk5NPek5L+3fPPfe4mJgYl5eXF3B/O3z4sH+M1efCBh0ozjn35JNPutatW7vw8HDXq1cvt3nzZv911157rRs1alTA+FWrVrnLLrvMhYeHu86dO7tXX3014Pqqqio3depU5/F4XEREhOvfv7/bvXv3+VjKKdVkjW3atHGSql2mT5/unHPu8OHDbsCAAe6iiy5yjRs3dm3atHFjx46ts3/8navZ+iZMmOAf6/F43E033eS2bdsWcD5re1jT++jHH3/sJLk333yz2rms7d+Jbzn95eXEmkaNGuWuvfbaare54oorXHh4uLvkkkvc4sWLq533dH9n51tN13jttdeedrxzP31rdXx8vAsPD3e/+c1v3PDhw93evXvP78L+T03XN2vWLHfppZe6yMhI17x5c9evXz+3YcOGaue1sofnch8tKytzUVFR7plnnjnpOS3t38nWJingcWX1uTDk/xYAAABgRoN9DwoAAKi/CBQAAGAOgQIAAMwhUAAAgDkECgAAMIdAAQAA5hAoAADAHAIFAACYQ6AAAABzCBQAAGAOgQIAAMwhUAAAgDn/C0WpEioY60y9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N15_M07_F10_K006_1.mat\n",
            "N15_M07_F10_K006_2.mat\n",
            "N15_M07_F10_K006_3.mat\n",
            "N15_M07_F10_K006_4.mat\n",
            "N15_M07_F10_K006_5.mat\n",
            "N15_M07_F10_K006_6.mat\n",
            "N15_M07_F10_K006_7.mat\n",
            "N15_M07_F10_K006_8.mat\n",
            "N15_M07_F10_K006_9.mat\n",
            "N15_M07_F10_K006_10.mat\n",
            "N15_M07_F10_K006_11.mat\n",
            "N15_M07_F10_K006_12.mat\n",
            "N15_M07_F10_K006_13.mat\n",
            "N15_M07_F10_K006_14.mat\n",
            "N15_M07_F10_K006_15.mat\n",
            "N15_M07_F10_K006_16.mat\n",
            "N15_M07_F10_K006_17.mat\n",
            "N15_M07_F10_K006_18.mat\n",
            "N15_M07_F10_K006_19.mat\n",
            "N15_M07_F10_K006_20.mat\n",
            "N15_M07_F10_KI17_1.mat\n",
            "N15_M07_F10_KI17_2.mat\n",
            "N15_M07_F10_KI17_3.mat\n",
            "N15_M07_F10_KI17_4.mat\n",
            "N15_M07_F10_KI17_5.mat\n",
            "N15_M07_F10_KI17_6.mat\n",
            "N15_M07_F10_KI17_7.mat\n",
            "N15_M07_F10_KI17_8.mat\n",
            "N15_M07_F10_KI17_9.mat\n",
            "N15_M07_F10_KI17_10.mat\n",
            "N15_M07_F10_KI17_11.mat\n",
            "N15_M07_F10_KI17_12.mat\n",
            "N15_M07_F10_KI17_13.mat\n",
            "N15_M07_F10_KI17_14.mat\n",
            "N15_M07_F10_KI17_15.mat\n",
            "N15_M07_F10_KI17_16.mat\n",
            "N15_M07_F10_KI17_17.mat\n",
            "N15_M07_F10_KI17_18.mat\n",
            "N15_M07_F10_KI17_19.mat\n",
            "N15_M07_F10_KI17_20.mat\n",
            "N15_M07_F10_KI18_1.mat\n",
            "N15_M07_F10_KI18_2.mat\n",
            "N15_M07_F10_KI18_3.mat\n",
            "N15_M07_F10_KI18_4.mat\n",
            "N15_M07_F10_KI18_5.mat\n",
            "N15_M07_F10_KI18_6.mat\n",
            "N15_M07_F10_KI18_7.mat\n",
            "N15_M07_F10_KI18_8.mat\n",
            "N15_M07_F10_KI18_9.mat\n",
            "N15_M07_F10_KI18_10.mat\n",
            "N15_M07_F10_KI18_11.mat\n",
            "N15_M07_F10_KI18_12.mat\n",
            "N15_M07_F10_KI18_13.mat\n",
            "N15_M07_F10_KI18_14.mat\n",
            "N15_M07_F10_KI18_15.mat\n",
            "N15_M07_F10_KI18_16.mat\n",
            "N15_M07_F10_KI18_17.mat\n",
            "N15_M07_F10_KI18_18.mat\n",
            "N15_M07_F10_KI18_19.mat\n",
            "N15_M07_F10_KI18_20.mat\n",
            "N15_M07_F10_KI21_1.mat\n",
            "N15_M07_F10_KI21_2.mat\n",
            "N15_M07_F10_KI21_3.mat\n",
            "N15_M07_F10_KI21_4.mat\n",
            "N15_M07_F10_KI21_5.mat\n",
            "N15_M07_F10_KI21_6.mat\n",
            "N15_M07_F10_KI21_7.mat\n",
            "N15_M07_F10_KI21_8.mat\n",
            "N15_M07_F10_KI21_9.mat\n",
            "N15_M07_F10_KI21_10.mat\n",
            "N15_M07_F10_KI21_11.mat\n",
            "N15_M07_F10_KI21_12.mat\n",
            "N15_M07_F10_KI21_13.mat\n",
            "N15_M07_F10_KI21_14.mat\n",
            "N15_M07_F10_KI21_15.mat\n",
            "N15_M07_F10_KI21_16.mat\n",
            "N15_M07_F10_KI21_17.mat\n",
            "N15_M07_F10_KI21_18.mat\n",
            "N15_M07_F10_KI21_19.mat\n",
            "N15_M07_F10_KI21_20.mat\n",
            "N15_M07_F10_KA22_1.mat\n",
            "N15_M07_F10_KA22_2.mat\n",
            "N15_M07_F10_KA22_3.mat\n",
            "N15_M07_F10_KA22_4.mat\n",
            "N15_M07_F10_KA22_5.mat\n",
            "N15_M07_F10_KA22_6.mat\n",
            "N15_M07_F10_KA22_7.mat\n",
            "N15_M07_F10_KA22_8.mat\n",
            "N15_M07_F10_KA22_9.mat\n",
            "N15_M07_F10_KA22_10.mat\n",
            "N15_M07_F10_KA22_11.mat\n",
            "N15_M07_F10_KA22_12.mat\n",
            "N15_M07_F10_KA22_13.mat\n",
            "N15_M07_F10_KA22_14.mat\n",
            "N15_M07_F10_KA22_15.mat\n",
            "N15_M07_F10_KA22_16.mat\n",
            "N15_M07_F10_KA22_17.mat\n",
            "N15_M07_F10_KA22_18.mat\n",
            "N15_M07_F10_KA22_19.mat\n",
            "N15_M07_F10_KA22_20.mat\n",
            "N15_M07_F10_KA30_3.mat\n",
            "N15_M07_F10_KA30_5.mat\n",
            "N15_M07_F10_KA30_9.mat\n",
            "N15_M07_F10_KA30_10.mat\n",
            "N15_M07_F10_KA30_11.mat\n",
            "N15_M07_F10_KA30_12.mat\n",
            "N15_M07_F10_KA30_14.mat\n",
            "N15_M07_F10_KA30_15.mat\n",
            "N15_M07_F10_KA30_16.mat\n",
            "N15_M07_F10_KA30_17.mat\n",
            "N15_M07_F10_KA30_19.mat\n",
            "N15_M07_F10_KA30_2.mat\n",
            "N15_M07_F10_KA30_4.mat\n",
            "N15_M07_F10_KA30_6.mat\n",
            "N15_M07_F10_KA30_7.mat\n",
            "N15_M07_F10_KA30_20.mat\n",
            "N15_M07_F10_KA30_1.mat\n",
            "N15_M07_F10_KA30_8.mat\n",
            "N15_M07_F10_KA30_13.mat\n",
            "N15_M07_F10_KA30_18.mat\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "training_dataset, testing_dataset = getDataset(code,signal=\"vibration\",width=256000,ratios=\"6:5\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1oH_9QXjCtJh"
      },
      "outputs": [],
      "source": [
        "training_dataloader = DataLoader(training_dataset, batch_size=32, shuffle=True);\n",
        "testing_dataloader = DataLoader(testing_dataset, batch_size=32, shuffle=True);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformer Model Creation"
      ],
      "metadata": {
        "id": "WMJHxiHHHsvZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "voNvaz4GCv43"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, seq_len=250, input_dim=1024, d_model=128, nhead=8, num_encoder_layers=4, dim_feedforward=256, num_classes=3):\n",
        "        super(Transformer, self).__init__();\n",
        "\n",
        "        self.positional_encoding = nn.Embedding(seq_len, input_dim);\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model = input_dim,\n",
        "                                                   nhead = nhead,\n",
        "                                                   dim_feedforward = dim_feedforward,\n",
        "                                                   activation='gelu',\n",
        "                                                   batch_first = True);\n",
        "\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers = num_encoder_layers\n",
        "        );\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, seq_len//2);\n",
        "        self.fc2 = nn.Linear(seq_len//2, 3);\n",
        "\n",
        "        self.gelu = nn.GELU();\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, input_dim = x.shape;\n",
        "\n",
        "        x = x + self.positional_encoding(\n",
        "            torch.arange(0, seq_len).to(device)\n",
        "        );\n",
        "\n",
        "        x = self.transformer_encoder(x);\n",
        "\n",
        "        x = self.fc1(x);\n",
        "        x = self.gelu(x);\n",
        "\n",
        "        x = self.fc2(x);\n",
        "\n",
        "        return x;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOKrVhovCxXj",
        "outputId": "0b8e23d5-ecce-4684-91fb-ea06d1c46979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformer(\n",
            "  (positional_encoding): Embedding(250, 1024)\n",
            "  (transformer_encoder): TransformerEncoder(\n",
            "    (layers): ModuleList(\n",
            "      (0-3): 4 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fc1): Linear(in_features=1024, out_features=125, bias=True)\n",
            "  (fc2): Linear(in_features=125, out_features=3, bias=True)\n",
            "  (gelu): GELU(approximate='none')\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = Transformer();\n",
        "model.to(device);\n",
        "\n",
        "print(model);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ienb5vtVCyss"
      },
      "outputs": [],
      "source": [
        "loss = nn.CrossEntropyLoss();\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.00001);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BmtfqrCYCztQ"
      },
      "outputs": [],
      "source": [
        "accuracy = Accuracy(task=\"multiclass\", num_classes=3).to(device);\n",
        "precision = Precision(task=\"multiclass\", num_classes=3).to(device);\n",
        "recall = Recall(task=\"multiclass\", num_classes=3).to(device);\n",
        "f1_score = F1Score(task=\"multiclass\", num_classes=3).to(device);\n",
        "conf_matrix_metric = ConfusionMatrix(task=\"multiclass\", num_classes=3).to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6rbCccbaC1bz"
      },
      "outputs": [],
      "source": [
        "result_dir = \"/content/drive/MyDrive/Results/Transformer\";\n",
        "if not os.path.exists(result_dir):\n",
        "    os.makedirs(result_dir);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BCx_O4f3C2gn"
      },
      "outputs": [],
      "source": [
        "epochs = 100;"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Training"
      ],
      "metadata": {
        "id": "ZjSRdnbUHy_r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW4yVoPTC3zl",
        "outputId": "7b9938cb-b3b5-459e-eb07-2da71e2c9c56",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 | Train Loss: 1.0775 | Test Loss: 1.3985 | Train Acc: 0.4273 | Test Acc: 0.1615 | Train F1: 0.4273 | Test F1: 0.1615\n",
            "Epoch 2/100 | Train Loss: 1.0381 | Test Loss: 1.1674 | Train Acc: 0.4534 | Test Acc: 0.1693 | Train F1: 0.4534 | Test F1: 0.1693\n",
            "Epoch 3/100 | Train Loss: 0.9787 | Test Loss: 1.2865 | Train Acc: 0.5733 | Test Acc: 0.1693 | Train F1: 0.5733 | Test F1: 0.1693\n",
            "Epoch 4/100 | Train Loss: 0.7303 | Test Loss: 1.4224 | Train Acc: 0.6429 | Test Acc: 0.2995 | Train F1: 0.6429 | Test F1: 0.2995\n",
            "Epoch 5/100 | Train Loss: 0.2375 | Test Loss: 3.9817 | Train Acc: 0.9630 | Test Acc: 0.2005 | Train F1: 0.9630 | Test F1: 0.2005\n",
            "Epoch 6/100 | Train Loss: 0.0814 | Test Loss: 3.9682 | Train Acc: 0.9815 | Test Acc: 0.3281 | Train F1: 0.9815 | Test F1: 0.3281\n",
            "Epoch 7/100 | Train Loss: 0.0331 | Test Loss: 5.1569 | Train Acc: 0.9955 | Test Acc: 0.2812 | Train F1: 0.9955 | Test F1: 0.2812\n",
            "Epoch 8/100 | Train Loss: 0.0033 | Test Loss: 6.2578 | Train Acc: 1.0000 | Test Acc: 0.2396 | Train F1: 1.0000 | Test F1: 0.2396\n",
            "Epoch 9/100 | Train Loss: 0.0028 | Test Loss: 6.6620 | Train Acc: 1.0000 | Test Acc: 0.2240 | Train F1: 1.0000 | Test F1: 0.2240\n",
            "Epoch 10/100 | Train Loss: 0.0004 | Test Loss: 7.0258 | Train Acc: 1.0000 | Test Acc: 0.2083 | Train F1: 1.0000 | Test F1: 0.2083\n",
            "Epoch 11/100 | Train Loss: 0.0003 | Test Loss: 7.0945 | Train Acc: 1.0000 | Test Acc: 0.2083 | Train F1: 1.0000 | Test F1: 0.2083\n",
            "Epoch 12/100 | Train Loss: 0.0003 | Test Loss: 7.1830 | Train Acc: 1.0000 | Test Acc: 0.2031 | Train F1: 1.0000 | Test F1: 0.2031\n",
            "Epoch 13/100 | Train Loss: 0.0003 | Test Loss: 7.1542 | Train Acc: 1.0000 | Test Acc: 0.2109 | Train F1: 1.0000 | Test F1: 0.2109\n",
            "Epoch 14/100 | Train Loss: 0.0003 | Test Loss: 7.1649 | Train Acc: 1.0000 | Test Acc: 0.2083 | Train F1: 1.0000 | Test F1: 0.2083\n",
            "Epoch 15/100 | Train Loss: 0.0003 | Test Loss: 7.0962 | Train Acc: 1.0000 | Test Acc: 0.2135 | Train F1: 1.0000 | Test F1: 0.2135\n",
            "Epoch 16/100 | Train Loss: 0.0002 | Test Loss: 7.1608 | Train Acc: 1.0000 | Test Acc: 0.2057 | Train F1: 1.0000 | Test F1: 0.2057\n",
            "Epoch 17/100 | Train Loss: 0.0002 | Test Loss: 7.1452 | Train Acc: 1.0000 | Test Acc: 0.2109 | Train F1: 1.0000 | Test F1: 0.2109\n",
            "Epoch 18/100 | Train Loss: 0.0002 | Test Loss: 7.1123 | Train Acc: 1.0000 | Test Acc: 0.2109 | Train F1: 1.0000 | Test F1: 0.2109\n",
            "Epoch 19/100 | Train Loss: 0.0002 | Test Loss: 7.1972 | Train Acc: 1.0000 | Test Acc: 0.2005 | Train F1: 1.0000 | Test F1: 0.2005\n",
            "Epoch 20/100 | Train Loss: 0.0002 | Test Loss: 7.1481 | Train Acc: 1.0000 | Test Acc: 0.2109 | Train F1: 1.0000 | Test F1: 0.2109\n",
            "Epoch 21/100 | Train Loss: 0.0002 | Test Loss: 7.0933 | Train Acc: 1.0000 | Test Acc: 0.2135 | Train F1: 1.0000 | Test F1: 0.2135\n",
            "Epoch 22/100 | Train Loss: 0.0002 | Test Loss: 7.0962 | Train Acc: 1.0000 | Test Acc: 0.2109 | Train F1: 1.0000 | Test F1: 0.2109\n",
            "Epoch 23/100 | Train Loss: 0.0002 | Test Loss: 7.1254 | Train Acc: 1.0000 | Test Acc: 0.2109 | Train F1: 1.0000 | Test F1: 0.2109\n",
            "Epoch 24/100 | Train Loss: 0.0002 | Test Loss: 7.1000 | Train Acc: 1.0000 | Test Acc: 0.2109 | Train F1: 1.0000 | Test F1: 0.2109\n",
            "Epoch 25/100 | Train Loss: 0.0002 | Test Loss: 7.1398 | Train Acc: 1.0000 | Test Acc: 0.2057 | Train F1: 1.0000 | Test F1: 0.2057\n",
            "Epoch 26/100 | Train Loss: 0.0002 | Test Loss: 7.1428 | Train Acc: 1.0000 | Test Acc: 0.2057 | Train F1: 1.0000 | Test F1: 0.2057\n",
            "\n",
            "Epoch 27/100 | Train Loss: 0.0002 | Test Loss: 7.1096 | Train Acc: 1.0000 | Test Acc: 0.2083 | Train F1: 1.0000 | Test F1: 0.2083\n",
            "Epoch 28/100 | Train Loss: 0.0002 | Test Loss: 7.2005 | Train Acc: 1.0000 | Test Acc: 0.2031 | Train F1: 1.0000 | Test F1: 0.2031\n",
            "Epoch 29/100 | Train Loss: 0.0002 | Test Loss: 7.1665 | Train Acc: 1.0000 | Test Acc: 0.2057 | Train F1: 1.0000 | Test F1: 0.2057\n",
            "Epoch 30/100 | Train Loss: 0.0002 | Test Loss: 7.1580 | Train Acc: 1.0000 | Test Acc: 0.2083 | Train F1: 1.0000 | Test F1: 0.2083\n",
            "Epoch 31/100 | Train Loss: 0.0001 | Test Loss: 7.1692 | Train Acc: 1.0000 | Test Acc: 0.2031 | Train F1: 1.0000 | Test F1: 0.2031\n",
            "Epoch 32/100 | Train Loss: 0.0001 | Test Loss: 7.1684 | Train Acc: 1.0000 | Test Acc: 0.2031 | Train F1: 1.0000 | Test F1: 0.2031\n",
            "Epoch 33/100 | Train Loss: 0.0001 | Test Loss: 7.0924 | Train Acc: 1.0000 | Test Acc: 0.2083 | Train F1: 1.0000 | Test F1: 0.2083\n",
            "Epoch 34/100 | Train Loss: 0.0001 | Test Loss: 7.1938 | Train Acc: 1.0000 | Test Acc: 0.2109 | Train F1: 1.0000 | Test F1: 0.2109\n",
            "Epoch 35/100 | Train Loss: 0.0001 | Test Loss: 7.0491 | Train Acc: 1.0000 | Test Acc: 0.2240 | Train F1: 1.0000 | Test F1: 0.2240\n",
            "Epoch 36/100 | Train Loss: 0.0001 | Test Loss: 7.0989 | Train Acc: 1.0000 | Test Acc: 0.2422 | Train F1: 1.0000 | Test F1: 0.2422\n",
            "Epoch 37/100 | Train Loss: 0.0001 | Test Loss: 7.1803 | Train Acc: 1.0000 | Test Acc: 0.2344 | Train F1: 1.0000 | Test F1: 0.2344\n",
            "Epoch 38/100 | Train Loss: 0.0001 | Test Loss: 7.1932 | Train Acc: 1.0000 | Test Acc: 0.2318 | Train F1: 1.0000 | Test F1: 0.2318\n",
            "Epoch 39/100 | Train Loss: 0.0001 | Test Loss: 7.2086 | Train Acc: 1.0000 | Test Acc: 0.2318 | Train F1: 1.0000 | Test F1: 0.2318\n",
            "Epoch 40/100 | Train Loss: 0.0001 | Test Loss: 7.2623 | Train Acc: 1.0000 | Test Acc: 0.2292 | Train F1: 1.0000 | Test F1: 0.2292\n",
            "Epoch 41/100 | Train Loss: 0.0001 | Test Loss: 7.1929 | Train Acc: 1.0000 | Test Acc: 0.2396 | Train F1: 1.0000 | Test F1: 0.2396\n",
            "Epoch 42/100 | Train Loss: 0.0001 | Test Loss: 7.2800 | Train Acc: 1.0000 | Test Acc: 0.2292 | Train F1: 1.0000 | Test F1: 0.2292\n",
            "Epoch 43/100 | Train Loss: 0.0001 | Test Loss: 7.2981 | Train Acc: 1.0000 | Test Acc: 0.2292 | Train F1: 1.0000 | Test F1: 0.2292\n",
            "Epoch 44/100 | Train Loss: 0.0001 | Test Loss: 7.2255 | Train Acc: 1.0000 | Test Acc: 0.2422 | Train F1: 1.0000 | Test F1: 0.2422\n",
            "Epoch 45/100 | Train Loss: 0.0001 | Test Loss: 7.2893 | Train Acc: 1.0000 | Test Acc: 0.2370 | Train F1: 1.0000 | Test F1: 0.2370\n",
            "Epoch 46/100 | Train Loss: 0.0001 | Test Loss: 7.2362 | Train Acc: 1.0000 | Test Acc: 0.2422 | Train F1: 1.0000 | Test F1: 0.2422\n",
            "Epoch 47/100 | Train Loss: 0.0001 | Test Loss: 7.2861 | Train Acc: 1.0000 | Test Acc: 0.2370 | Train F1: 1.0000 | Test F1: 0.2370\n",
            "Epoch 48/100 | Train Loss: 0.0001 | Test Loss: 7.3758 | Train Acc: 1.0000 | Test Acc: 0.2344 | Train F1: 1.0000 | Test F1: 0.2344\n",
            "Epoch 49/100 | Train Loss: 0.0001 | Test Loss: 7.3438 | Train Acc: 1.0000 | Test Acc: 0.2396 | Train F1: 1.0000 | Test F1: 0.2396\n",
            "Epoch 50/100 | Train Loss: 0.0001 | Test Loss: 7.1892 | Train Acc: 1.0000 | Test Acc: 0.2526 | Train F1: 1.0000 | Test F1: 0.2526\n",
            "Epoch 51/100 | Train Loss: 0.0001 | Test Loss: 7.2908 | Train Acc: 1.0000 | Test Acc: 0.2474 | Train F1: 1.0000 | Test F1: 0.2474\n",
            "Epoch 52/100 | Train Loss: 0.0001 | Test Loss: 7.3310 | Train Acc: 1.0000 | Test Acc: 0.2448 | Train F1: 1.0000 | Test F1: 0.2448\n",
            "Epoch 53/100 | Train Loss: 0.0001 | Test Loss: 7.3700 | Train Acc: 1.0000 | Test Acc: 0.2396 | Train F1: 1.0000 | Test F1: 0.2396\n",
            "Epoch 54/100 | Train Loss: 0.0001 | Test Loss: 7.4480 | Train Acc: 1.0000 | Test Acc: 0.2344 | Train F1: 1.0000 | Test F1: 0.2344\n",
            "Epoch 55/100 | Train Loss: 0.0001 | Test Loss: 7.2852 | Train Acc: 1.0000 | Test Acc: 0.2448 | Train F1: 1.0000 | Test F1: 0.2448\n",
            "Epoch 56/100 | Train Loss: 0.0001 | Test Loss: 7.4280 | Train Acc: 1.0000 | Test Acc: 0.2370 | Train F1: 1.0000 | Test F1: 0.2370\n",
            "Epoch 57/100 | Train Loss: 0.0001 | Test Loss: 7.4071 | Train Acc: 1.0000 | Test Acc: 0.2370 | Train F1: 1.0000 | Test F1: 0.2370\n",
            "Epoch 58/100 | Train Loss: 0.0001 | Test Loss: 7.3712 | Train Acc: 1.0000 | Test Acc: 0.2448 | Train F1: 1.0000 | Test F1: 0.2448\n",
            "Epoch 59/100 | Train Loss: 0.0001 | Test Loss: 7.4279 | Train Acc: 1.0000 | Test Acc: 0.2396 | Train F1: 1.0000 | Test F1: 0.2396\n",
            "Epoch 60/100 | Train Loss: 0.0001 | Test Loss: 7.4701 | Train Acc: 1.0000 | Test Acc: 0.2370 | Train F1: 1.0000 | Test F1: 0.2370\n",
            "Epoch 61/100 | Train Loss: 0.0001 | Test Loss: 7.4887 | Train Acc: 1.0000 | Test Acc: 0.2344 | Train F1: 1.0000 | Test F1: 0.2344\n",
            "Epoch 62/100 | Train Loss: 0.0001 | Test Loss: 7.4409 | Train Acc: 1.0000 | Test Acc: 0.2396 | Train F1: 1.0000 | Test F1: 0.2396\n",
            "Epoch 63/100 | Train Loss: 0.0001 | Test Loss: 7.4373 | Train Acc: 1.0000 | Test Acc: 0.2422 | Train F1: 1.0000 | Test F1: 0.2422\n",
            "Epoch 64/100 | Train Loss: 0.0001 | Test Loss: 7.5204 | Train Acc: 1.0000 | Test Acc: 0.2370 | Train F1: 1.0000 | Test F1: 0.2370\n",
            "Epoch 65/100 | Train Loss: 0.0001 | Test Loss: 7.4955 | Train Acc: 1.0000 | Test Acc: 0.2396 | Train F1: 1.0000 | Test F1: 0.2396\n",
            "Epoch 66/100 | Train Loss: 0.0001 | Test Loss: 7.4721 | Train Acc: 1.0000 | Test Acc: 0.2422 | Train F1: 1.0000 | Test F1: 0.2422\n"
          ]
        }
      ],
      "source": [
        "metrics_list = [];\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    train_loss_per_epoch = [];\n",
        "    test_loss_per_epcoh = [];\n",
        "\n",
        "    train_acc_per_epoch = [];\n",
        "    test_acc_per_epoch = [];\n",
        "\n",
        "    train_precision_per_epoch = [];\n",
        "    test_precision_per_epoch = [];\n",
        "\n",
        "    train_recall_per_epoch = [];\n",
        "    test_recall_per_epoch = [];\n",
        "\n",
        "    train_f1_per_epoch = [];\n",
        "    test_f1_per_epoch = [];\n",
        "\n",
        "    traing_cf = np.zeros((3,3));\n",
        "    test_cf = np.zeros((3,3));\n",
        "\n",
        "    model.train();\n",
        "    for x, y in training_dataloader:\n",
        "        optimizer.zero_grad();\n",
        "        x = x.to(device);\n",
        "        y = y.to(device);\n",
        "\n",
        "        y_pred = model(x);\n",
        "\n",
        "        loss_value = loss(y_pred.view(-1,3), y.view(-1));\n",
        "\n",
        "        loss_value.backward();\n",
        "        optimizer.step();\n",
        "\n",
        "        y_pred = y_pred.argmax(dim=-1);\n",
        "\n",
        "        y_pred_mm,_ = torch.mode(y_pred, dim=-1);\n",
        "        y_mm,_ = torch.mode(y, dim=-1);\n",
        "\n",
        "        acc = accuracy(y_pred_mm, y_mm);\n",
        "        prec = precision(y_pred_mm, y_mm);\n",
        "        rec = recall(y_pred_mm, y_mm);\n",
        "        f1 = f1_score(y_pred_mm, y_mm);\n",
        "        conf_matrix = conf_matrix_metric(y_pred_mm, y_mm);\n",
        "\n",
        "        traing_cf += conf_matrix.cpu().numpy();\n",
        "\n",
        "        train_loss_per_epoch.append(loss_value.item());\n",
        "        train_acc_per_epoch.append(acc.item());\n",
        "        train_precision_per_epoch.append(prec.item());\n",
        "        train_recall_per_epoch.append(rec.item());\n",
        "        train_f1_per_epoch.append(f1.item());\n",
        "\n",
        "    model.eval();\n",
        "    with torch.no_grad():\n",
        "        for x, y in testing_dataloader:\n",
        "            x = x.to(device);\n",
        "            y = y.to(device);\n",
        "\n",
        "            y_pred = model(x);\n",
        "\n",
        "            loss_value = loss(y_pred.view(-1,3), y.view(-1));\n",
        "\n",
        "            y_pred = y_pred.argmax(dim=-1);\n",
        "\n",
        "            y_pred_mm,_ = torch.mode(y_pred, dim=-1);\n",
        "            y_mm,_ = torch.mode(y, dim=-1);\n",
        "\n",
        "            acc = accuracy(y_pred_mm, y_mm);\n",
        "            prec = precision(y_pred_mm, y_mm);\n",
        "            rec = recall(y_pred_mm, y_mm);\n",
        "            f1 = f1_score(y_pred_mm, y_mm);\n",
        "            conf_matrix = conf_matrix_metric(y_pred_mm, y_mm);\n",
        "\n",
        "            test_cf += conf_matrix.cpu().numpy();\n",
        "\n",
        "            test_loss_per_epcoh.append(loss_value.item());\n",
        "            test_acc_per_epoch.append(acc.item());\n",
        "            test_precision_per_epoch.append(prec.item());\n",
        "            test_recall_per_epoch.append(rec.item());\n",
        "            test_f1_per_epoch.append(f1.item());\n",
        "\n",
        "\n",
        "    metrics_list.append({\n",
        "        \"train_loss\": np.mean(train_loss_per_epoch),\n",
        "        \"test_loss\": np.mean(test_loss_per_epcoh),\n",
        "        \"train_acc\": np.mean(train_acc_per_epoch),\n",
        "        \"test_acc\": np.mean(test_acc_per_epoch),\n",
        "        \"train_precision\": np.mean(train_precision_per_epoch),\n",
        "        \"test_precision\": np.mean(test_precision_per_epoch),\n",
        "        \"train_recall\": np.mean(train_recall_per_epoch),\n",
        "        \"test_recall\": np.mean(test_recall_per_epoch),\n",
        "        \"train_f1\": np.mean(train_f1_per_epoch),\n",
        "        \"test_f1\": np.mean(test_f1_per_epoch),\n",
        "        \"train_cf\": json.dumps(traing_cf.tolist()),\n",
        "        \"test_cf\": json.dumps(test_cf.tolist())\n",
        "    });\n",
        "\n",
        "    maxx = max(metrics_list, key=lambda x: x[\"test_f1\"]);\n",
        "\n",
        "    if maxx[\"test_f1\"] <= metrics_list[-1][\"test_f1\"]:\n",
        "        torch.save(model.state_dict(), os.path.join(result_dir,\"bb_mm.pth\"));\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {metrics_list[-1]['train_loss']:.4f} | Test Loss: {metrics_list[-1]['test_loss']:.4f} | Train Acc: {metrics_list[-1]['train_acc']:.4f} | Test Acc: {metrics_list[-1]['test_acc']:.4f} | Train F1: {metrics_list[-1]['train_f1']:.4f} | Test F1: {metrics_list[-1]['test_f1']:.4f}\");"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}